{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 17:44:57.529 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'humor': 4213, 'wiki': 4181, 'proverbs': 831, 'reuters': 4186}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Query 1\n",
    "import collections\n",
    "count_labels = collections.Counter([traindataset[i][1] for i in range(len(traindataset))])\n",
    "{v: count_labels[v] for v in count_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'humor': 0.31414510476474533,\n",
       " 'wiki': 0.31175900380284843,\n",
       " 'proverbs': 0.06196405935426143,\n",
       " 'reuters': 0.3121318320781448}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Query 2\n",
    "import collections\n",
    "count_labels = collections.Counter([traindataset[i][1] for i in range(len(traindataset))])\n",
    "{v: count_labels[v] / len(traindataset) for v in count_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Green\">*Toelichting student*</span> \n",
    "\n",
    "Op basis van de uitkomsten van query 1 blijkt dat de categorieën 'humor', 'wiki' en 'reuters' in de traindataset een nagenoeg gelijk aantal observaties bevat. De categorie 'proverbs' bevat daarentegen een aanzienlijk lager aantal observaties. \n",
    "\n",
    "Middels query 2 is per categorie berekend hoe groot de kans is dat een willekeurige observatie toebehoort tot een specifieke categorie. Conform de uitkomsten van query 1 blijkt dat de kans dat een observatie afkomstig is van de categorieën 'humor'(31,4%), 'wiki'(31,2%) en 'reuters'(31,2%) bijna gelijk is, terwijl de kans dat een willekeurige observatie toebehoort tot de categorie 'proverbs' met 6,2% veel lager is. Bij een normale verdeling van de data zou iedere categorie een gelijke kans hebben (namelijk 25%) dat een willekeurige observatie van een specifieke categorie afkomstig is. \n",
    "\n",
    "In dit geval bevat de traindataset geen normale verdeling. Een nadeel hiervan is dat het model voor de categorie 'Proverbs' minder voorbeelden beschikbaar heeft om op te trainen. Hierdoor ontstaat het risico dat, gezien het beperkte aantal observaties, het model minder goed in staat is om 'proverbs' zinnen te herkennen waardoor het model minder accuraat wordt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        if label in d.keys():\n",
    "            return d[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 29]),\n",
       " tensor([2, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 2, 1, 2, 2, 1, 3, 0, 2, 2, 0, 0, 1,\n",
       "         0, 2, 0, 0, 2, 0, 1, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "import torch\n",
    "\n",
    "metrics = [metrics.F1Score(), metrics.Accuracy()] ## Op basis van theorie beste metrics + onderbouwing toevoegen.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Green\">*Toelichting student*</span> \n",
    "\n",
    "Op te bepalen welke metrices het meest geschikt zijn voor deze NLP-dataset, heb ik op internet research gedaan. Op de website van [Towards data science](https://towardsdatascience.com/the-most-common-evaluation-metrics-in-nlp-ced6a763ac8b) heb ik een artikel gevonden waarin wordt beschreven dat onder andere de metrices 'Accuracy', 'Precision', 'Recall' en 'F1 Score' geschikt zijn voor het evalueren van de werking van een NLP-model. Ik het gekozen voor de metrices 'Accuracy' en 'F1 Score'. De 'Accuracy' metrics is tijdens de lessen veelvuldig gebruikt en geeft goed inzicht in de presaties van een model. De F1 score vind ik een interessante metrics omdat hierin de 'Precision' en 'Recall' gecombineerd zijn. Daarnaast heb ik in een eerder noteboek gelezen dat de F1-score bij uitstek geschikt is voor ongebalanceerde datasets. \n",
    "\n",
    "Aangezien de opdracht een classificatie vraagstuk betreft, heb ik gekozen om de 'CrossEntropyLoss' als loss function te implementeren. Deze functie is namelijk zeer geschikt voor classificatie vraagstukken. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = settings.log_dir\n",
    "from src.models import rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "model = rnn.NLPmodel(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Green\">*Toelichting student*</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. De traindataset bevat 13411 observaties. Op basis van een batchsize van 32 observaties is het mogelijk om 419 gehele batches te creëren, waarna er nog 3 losse observaties resteren. Om alle observaties te batchen zijn dus 420 batches benodigd.\n",
      "\n",
      "2. De gehele dataset (train- en testdataset) bevat 16764 observaties. Op basis van een batchsize met 32 observaties en een train_step van 25 observaties, zijn 21 epochs benodigd om alle observaties door het model te laten analyseren. \n",
      "\n",
      "3. De traindataset bevat 13411 observaties. Op basis van een batchsize met 32 observaties en een train_step van 25 observaties, zijn 17 epochs benodigd om alle observaties door het model te laten analyseren. \n",
      "\n",
      "4. Doordat tijdens het trainen van het model enkel de observaties afkomstig uit de traindataset worden geanalyseerd, zijn 17 epochs voldoende om alle observaties door het model te laten analyseren. Tijdens onderdeel 6 'Tune the model' zal onder andere met aantal epochs worden geëxperimenteerd.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'''1. De traindataset bevat {len(traindataset)} observaties. Op basis van een batchsize van {32} observaties is het mogelijk om {round(len(traindataset)/32)} gehele batches te creëren, waarna er nog {len(traindataset)-(32*(round(len(traindataset)/32)))} losse observaties resteren. Om alle observaties te batchen zijn dus {math.ceil(len(traindataset)/32)} batches benodigd.''')\n",
    "print()\n",
    "print(f'''2. De gehele dataset (train- en testdataset) bevat {(len(traindataset) + len(testdataset))} observaties. Op basis van een batchsize met 32 observaties en een train_step van 25 observaties, zijn {math.ceil((len(traindataset) + len(testdataset))/(32*25))} epochs benodigd om alle observaties door het model te laten analyseren. ''')\n",
    "print()\n",
    "print(f'''3. De traindataset bevat {len(traindataset)} observaties. Op basis van een batchsize met 32 observaties en een train_step van 25 observaties, zijn {math.ceil(len(traindataset)/(32*25))} epochs benodigd om alle observaties door het model te laten analyseren. ''')\n",
    "print()\n",
    "print(f'''4. Doordat tijdens het trainen van het model enkel de observaties afkomstig uit de traindataset worden geanalyseerd, zijn {math.ceil(len(traindataset)/(32*25))} epochs voldoende om alle observaties door het model te laten analyseren. Tijdens onderdeel 6 'Tune the model' zal onder andere met aantal epochs worden geëxperimenteerd.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 17:44:59.958588: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-04 17:44:59.958652: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-07-04 17:45:02.530 | INFO     | src.data.data_tools:dir_add_timestamp:67 - Logging to ../tune/20220704-1745\n",
      "100%|██████████| 25/25 [00:04<00:00,  6.06it/s]\n",
      "2022-07-04 17:45:07.734 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2929 test 1.2418 metric ['0.2334', '0.4113']\n",
      "100%|██████████| 25/25 [00:03<00:00,  7.05it/s]\n",
      "2022-07-04 17:45:11.917 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 1.2431 test 1.2336 metric ['0.2295', '0.3950']\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.19it/s]\n",
      "2022-07-04 17:45:15.193 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 1.1894 test 1.1283 metric ['0.3314', '0.4825']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.68it/s]\n",
      "2022-07-04 17:45:18.009 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 1.0943 test 0.9748 metric ['0.3633', '0.5575']\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.69it/s]\n",
      "2022-07-04 17:45:21.038 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.9152 test 0.9218 metric ['0.3630', '0.5587']\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.68it/s]\n",
      "2022-07-04 17:45:23.997 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.8484 test 0.7867 metric ['0.5414', '0.6750']\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.39it/s]\n",
      "2022-07-04 17:45:27.049 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.7591 test 0.6652 metric ['0.5899', '0.7488']\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.41it/s]\n",
      "2022-07-04 17:45:30.210 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.6830 test 0.5803 metric ['0.6455', '0.7975']\n",
      "100%|██████████| 25/25 [00:01<00:00, 12.66it/s]\n",
      "2022-07-04 17:45:32.800 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.5916 test 0.5704 metric ['0.6599', '0.7987']\n",
      "100%|██████████| 25/25 [00:01<00:00, 12.59it/s]\n",
      "2022-07-04 17:45:35.544 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.5565 test 0.5401 metric ['0.6642', '0.8187']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.23it/s]\n",
      "2022-07-04 17:45:38.452 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.5190 test 0.4607 metric ['0.6671', '0.8325']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.23it/s]\n",
      "2022-07-04 17:45:41.323 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.5136 test 0.5356 metric ['0.7346', '0.8175']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.33it/s]\n",
      "2022-07-04 17:45:44.180 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.4853 test 0.4177 metric ['0.7310', '0.8575']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.51it/s]\n",
      "2022-07-04 17:45:46.948 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.4674 test 0.3916 metric ['0.7171', '0.8650']\n",
      "100%|██████████| 25/25 [00:02<00:00, 12.44it/s]\n",
      "2022-07-04 17:45:49.580 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.4951 test 0.4391 metric ['0.7631', '0.8475']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.35it/s]\n",
      "2022-07-04 17:45:52.447 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.4790 test 0.4538 metric ['0.7170', '0.8413']\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.55it/s]\n",
      "2022-07-04 17:45:55.443 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.4249 test 0.4753 metric ['0.6596', '0.8175']\n",
      "100%|██████████| 17/17 [00:52<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=17,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Green\">*Toelichting student*</span> \n",
    "\n",
    "In onderstaande visual is goed zichtbaar dat het model tot aan epoch 11 zich vlot blijft ontwikkelen, waarna de leersnelheid wat afvlakt. Op basis van uitkomsten zou ik echter wel middels een experiment proberen om het aantal epochs te vergroten om vast te stellen of het model daadwerkelijk is uitgeleerd of dat het model zich nog verder kan ontwikkelen.  \n",
    "\n",
    "<img src=\"../figures/TensorBoard.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 15.0, 'Predicted'), Text(33.0, 0.5, 'Target')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "- What is a good metric here?\n",
    "- how is your answer to Q1 relevant here?\n",
    "- Is there something you could do to fix/improve things, after you see these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Green\">*Toelichting student*</span> \n",
    "\n",
    "<img src=\"../figures/Confusion_Matrix.png\">\n",
    "\n",
    "1. In de bovenstaande matrix is weergegeven hoe goed het model presteert op de testdataset. Uit de matrix kan worden afgeleid dat het model observaties voor de categoriën 'humor'(0), 'reuters'(1) en 'wiki'(2) goed kan voorspellen. Dit blijkt uit de hoge accuracy scores van tussen de 81,0% en 98,9%. De categorie 'proverbs'(3) scoort met een accuracy van 68,8% een stuk lager. Uit de matrix blijkt dat een deel van 'proverbs' observaties zijn toegekend aan de categorie 'wiki', maar dat andersom hier slechts beperkt sprake van is. Een mogelijke verklaring hiervan betreft de ongelijke verdeling van de traindataset waardoor voor de categorie 'proverbs'(3) minder observaties beschikbaar zijn geweest om het model goed op te kunnen trainen.<br>\n",
    "\n",
    "2. In de huidige matrix wordt de accuracy per categorie weergegeven. Afhankelijk van de doelstelling van het classificatie vraagstuk bieden de metrices 'Precision' en 'Recall' goed inzicht in de prestaties van een model. Indien een balans wordt gezocht tussen de metrices 'Precision' en 'Recall' is de 'F1 Score' een goed alternatief omdat hierin de metrices 'Precision' en 'Recall' zijn gecombineerd. Daarnaast sluit de F1-score goed aan bij de ongebalanceerde dataset. (Bron: [Toward Data Science](https://towardsdatascience.com/confusion-matrix-un-confused-1ba98dee0d7f))<br>\n",
    "\n",
    "3. Zoals deels in antwoord 1 beschreven scoort het model op basis van de gebruikte parameters goed bij het identificeren van observaties die toebehoren tot de categoriën 0 t/m 2. Voor wat betreft categorie 3 scoort het model minder goed. Dit wordt vermoedelijk veroorzaakt doordat de trainingset minder observaties bevat voor de categorie 'proverbs'(3) dan voor de andere categorieën. Het model heeft hierdoor minder voorbeelden beschikbaar om karakteristieken te identificeren die toebehoren tot de observaties van categorie 'proverbs'(3).<br>\n",
    "\n",
    "4. De trainingsdataset in ongelijk verdeeld doordat het aantal observaties voor de categorie 'proverbs'(3) veel lager uitvalt dan het aantal observaties voor de overige drie categoriën. Een gelijk verdeelde dataset kan de prestaties van een model verbeteren. Om een gelijk verdeelde dataset te creëren zijn grofweg twee opties mogelijk:\n",
    "* Undersampling: voor de categoriën met veel observaties wordt slechts een deel van de observaties gesampled zodat het aantal observaties per categorie in de train- en testdataset nagenoeg gelijk is.\n",
    "* Oversampling: voor de categorie met weinig observaties worden observaties gedupliceerd zodat een gelijk verdeelde dataset ontstaat. <br>\n",
    "\n",
    "In onderstaande afbeelding is het principe van oversampling en undersampling weergegeven.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*P93SeDGPGw0MhwvCcvVcXA.png\" />\n",
    "\n",
    "(Bron: [Toward Data Science](https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Green\">*Toelichting student*</span> \n",
    "\n",
    "Voor het tunen van het RNN-model (zonder attention layer) heb ik een zestal experimenten uitgevoerd met in totaal 47 trainsessies om het model te verbeteren en om inzicht te krijgen wat de impact van bepaalde variabelen zijn op de werking van het model. In deze eindopdracht zijn drie experimenten met de meest interessante uitkomsten of waarvan de verwachtingen het hoogst waren, nader toegelicht in de experimenten 1 t/m 4. Per experiment en trainsessie zijn alle variabelen en de uitkomsten van het model vastgelegd in een Excel-overzicht. Bij de beschrijving van de verschillende experimenten zijn de gebruikte variabelen inclusief uitkomsten weergegeven.\n",
    "\n",
    "Daarnaast ben ik als onderdeel van de bonusopdracht de uitdaging aangegaan om een attention layer toe te voegen aan het RNN-model om zo de toegevoegde waarde van het RNN-model te beschrijven en te visualiseren. Dit experiment is beschreven in experiment 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:Green\">*Experiment 1: Batch Size*</span> \n",
    "\n",
    "Middels het experimenteren met de batch size heb ik geprobeerd om een optimum te vinden waarbij het model het beste presteert. Hierbij heb ik gekozen om de batch size per trainsessie te verdubbelen van een batch size met 16 observaties tot een batch size met 256 observaties. In onderstaande tabel zijn alle variabelen weergegeven die tijdens de trainsessies zijn toegepast inclusief de tijdsduur per trainsessie en de scores van het model:\n",
    "<img src=\"../figures/Experiment_1_Batch_Size.png\">\n",
    "\n",
    "Op basis van de uitkomsten blijkt dat het model het best presteert bij een batch size met 64 observaties. De F1-score en de loss/train blijft zich bij een hogere batch size nog wel ontwikkelen, echter verslechterd de loss/test bij een hogere batch size. Vooral het verschil dat ontstaat tussen de loss/test en de loss/train is kenmerkend dat het model begint te overfitten. Tot en met een batch size van 64 observaties blijft dit verschillen beperkt, echter vanaf een batch size van 128 obeservaties wordt het verschil steeds groter. Het model wordt namelijk goed in het herkennen van de voorbeelden in de trainset en bereikt daardoor een hoge score, echter op de testset met nieuwe voorbeelden blijven de prestaties achter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:Green\">*Experiment 2: Hidden Size*</span> \n",
    "\n",
    "Middels het experimenteren met de hidden size heb ik geprobeerd om te onderzoeken wat het effect van de hidden size is op de prestaties van het model. Mijn hypothese was dat het model bij een te grote hidden size zou gaan overfitten, omdat het model teveel gaat letten op de kleine details in de data en doordoor generiekere kenmerken mist. Bij een te kleine hidden size daarentegen worden onderscheidende kenmerken niet goed geïdentificeerd. In onderstaande tabel zijn alle variabelen weergegeven die tijdens de trainsessies zijn toegepast inclusief de tijdsduur per trainsessie en de scores van het model:\n",
    "<img src=\"../figures/Experiment_2_Hidden_Size.png\">\n",
    "\n",
    "Op basis van de uitkomsten blijkt dat het model het best presteert bij een hidden size van 128. Een betere score wordt nog behaald bij een hidden size van 1028, echter is het verschil tussen de loss/test en de loss/train dermate groot dat ik zou opteren voor de een hidden size van 128, zodat het model meer voorspelbaar presteert zonder dat daarbij het risico ontstaat op overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:Green\">*Experiment 3: Epoch*</span>\n",
    "Op basis van de voorgaande experimenten bleek dat het model nog niet was uitgeleerd. Om die reden heb ik besloten om diverse experimenten te gaan uitvoeren waarbij het aantal epochs stapsgewijs worden vergroot. In onderstaande tabel zijn alle variabelen weergegeven die tijdens de trainsessies zijn toegepast inclusief de tijdsduur per trainsessie en de scores van het model: \n",
    "<img src=\"../figures/Experiment_3_Epoch.png\">\n",
    "\n",
    "Op basis van de uitkomsten van het model blijkt dat een hogere epoch slechts in beperkte mate invloed heeft op de prestaties van het model. De laagste lost/test score wordt bereikt bij een epoch van 25, echter zou mijn voorkeur uitgaan naar een epoch van 17 doordat het verschil tussen de loss/test en de loss/train bij dit epoch aantal beperkt blijft terwijl bij een epoch van 25 een aanzienlijk verschil onstaat. In onderstaande afbeelding zijn de uitkomsten weergegevan van trainsessie met 45 epochs:\n",
    "\n",
    "<img src=\"../figures/Experiment_3_Output.png\">\n",
    "\n",
    "Hieruit blijkt inderdaad dat de prestaties van het model (o.b.v. de loss/test, Accuracy en F1 score) na 17-20 epochs afzwakt of zelfs slechter gaat presteren terwijl de loss/train zich verder blijft verbeteren. Dit wordt veroorzaakt doordat het model bij een hogere epoch dezelfde voorbeelden krijgt aangeboden die het model herkent en daardoor een goede voorspelling kan geven. Opmerkelijk is dat de learning_rate gedurende de traincycles automatisch wordt aangepast. Deze aanpassing wordt veroorzaakt door de schedular die in het models is geïmplementeerd en ervoor zorgt dat de learning_rate wordt aangepast nadat het model onvoldoende leert na verloop van tijd.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:Green\">*Experiment 4: Optimizers & Learning rate*</span> \n",
    "\n",
    "Voor het laatste experiment met het RNN-model zonder Attention-Layer heb ik besloten om verschillende optimizers te testen met daarbij een wisselende learning rate. Eenzelfde soort experiment heb ik uitgevoerd op de MNIST-Fashion dataset waarbij de Adam, RMSprop en Adagrad optimizers nagenoeg gelijk presteerden. Doordat dit een ander type dataset betreft waarvoor een ander model wordt toegepast, verwacht ik andere uitkomsten tussen de verschillende modellen. In onderstaande tabel zijn alle variabelen weergegeven die tijdens de trainsessie zijn toegepast inclusief de tijdsduur per trainsessie en de scores van het model: \n",
    "<img src=\"../figures/Experiment_4_Optimizers.png\">\n",
    "\n",
    "Om de uitkomsten van dit experiment beter te visualiseren, heb ik besloten om voor de Loss/test, Accuracy, en F1-Score matrixen op te stellen waarin de uitkomsten zijn gevisualiseerd.\n",
    "\n",
    "#### Matrix Loss/Test\n",
    "<img src=\"../figures/Experiment_4_Output_Loss_Test.png\">\n",
    "\n",
    "#### Matrix Accuracy\n",
    "<img src=\"../figures/Experiment_4_Output_Accuracy.png\">\n",
    "\n",
    "#### Matrix F1-Score\n",
    "<img src=\"../figures/Experiment_4_Output_F1_Score.png\">\n",
    "\n",
    "\n",
    "Op basis van de hierboven weergegeven matrices blijkt dat wederom de optimizers Adam, RMSprop en Adagrad het best presteren, maar dat de optimizers zeer gevoelig zijn voor aanpassingen in de learning rate. Hieronder een korte analyse per optimizer.\n",
    "\n",
    "* Adam\n",
    "\n",
    "De optimizer Adam scoort overall het best. Een learning rate van 1,00E-02  resulteert in de hoogte score met een lost/test van 28%, een Accuracy van 89% en een F1-score van 87%. Bij een lagere learning rate scoort het model ronduit slecht.\n",
    "\n",
    "* SGD\n",
    "\n",
    "De optimizer SGD scoort het slechts van de vier geteste optimizers waarbij het model bij geen enkele learning rate in staat is om de data goed te classificeren, zelfs niet op basis van traindataset. De Loss/test uitkomsten tonen weinig variatie bij een wijziging van de learning rate.\n",
    "\n",
    "* Adagrad\n",
    "\n",
    "De Adagrad optimizer geeft bij een learning rate van 1,00E-01 de beste resultaten weer van de vier geteste optimizers en scoort bij een learning rate van 1,00E-02 zelf nog iets beter. Bij een learning rate van 1,00E-03 t/m 1,00E-05 scoort het model juist weer beduidend slechter.    \n",
    "\n",
    "* RMSprop\n",
    "\n",
    "De uitkomsten van de RMSprop optimizer zijn zeer wisselend. Bij een learning rate van 1,00E-01 presteert het model ondermaats, terwijl de optimizer bij een learning rate van 1,00E-02 t/m 1,00E-03 juist weer goed scoort met mooie resultaten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:Green\">*Experiment 5: RNN-model met attention layer*</span> \n",
    "\n",
    "Tijdens het laatste model is een experiment uitgevoerd waarbij het RRN-model is geupgrade met een attention layer. De code die is uitgebruikt voor dit experiment is hieronder weergegeven. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=64, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=64, preprocessor=preprocessor\n",
    ").stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = settings.log_dir\n",
    "from src.models import rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "model = rnn.AttentionNLP(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 17:45:56.493 | INFO     | src.data.data_tools:dir_add_timestamp:67 - Logging to ../tune/20220704-1745\n",
      "100%|██████████| 25/25 [00:04<00:00,  6.17it/s]\n",
      "2022-07-04 17:46:01.949 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.3208 test 0.9569 metric ['0.4834', '0.6388']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.31it/s]\n",
      "2022-07-04 17:46:07.294 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 0.7701 test 0.7401 metric ['0.5839', '0.7656']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.97it/s]\n",
      "2022-07-04 17:46:12.221 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 0.6406 test 0.5009 metric ['0.6898', '0.8387']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.83it/s]\n",
      "2022-07-04 17:46:17.397 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 0.5297 test 0.5215 metric ['0.6440', '0.8281']\n",
      "100%|██████████| 25/25 [00:04<00:00,  5.65it/s]\n",
      "2022-07-04 17:46:23.095 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.4564 test 0.4754 metric ['0.7354', '0.8506']\n",
      "100%|██████████| 25/25 [00:03<00:00,  7.15it/s]\n",
      "2022-07-04 17:46:27.909 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.4615 test 0.4070 metric ['0.7391', '0.8638']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.29it/s]\n",
      "2022-07-04 17:46:33.259 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.4221 test 0.3481 metric ['0.7948', '0.8894']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.54it/s]\n",
      "2022-07-04 17:46:38.315 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.3907 test 0.3717 metric ['0.8127', '0.8819']\n",
      "100%|██████████| 25/25 [00:03<00:00,  7.18it/s]\n",
      "2022-07-04 17:46:43.232 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.2887 test 0.3315 metric ['0.8191', '0.9012']\n",
      "100%|██████████| 25/25 [00:03<00:00,  7.14it/s]\n",
      "2022-07-04 17:46:48.075 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.2836 test 0.3086 metric ['0.8553', '0.9006']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.68it/s]\n",
      "2022-07-04 17:46:53.178 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.2726 test 0.3510 metric ['0.8005', '0.8862']\n",
      "100%|██████████| 25/25 [00:03<00:00,  7.19it/s]\n",
      "2022-07-04 17:46:57.908 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.2820 test 0.3100 metric ['0.8356', '0.9006']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.36it/s]\n",
      "2022-07-04 17:47:03.034 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.2551 test 0.3602 metric ['0.8272', '0.8869']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.80it/s]\n",
      "2022-07-04 17:47:07.975 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.2719 test 0.3468 metric ['0.8282', '0.8919']\n",
      "100%|██████████| 25/25 [00:03<00:00,  7.31it/s]\n",
      "2022-07-04 17:47:12.786 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.2274 test 0.3622 metric ['0.7987', '0.8750']\n",
      "100%|██████████| 25/25 [00:04<00:00,  5.87it/s]\n",
      "2022-07-04 17:47:18.347 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.2553 test 0.3059 metric ['0.8211', '0.8944']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.46it/s]\n",
      "2022-07-04 17:47:23.361 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.2053 test 0.3630 metric ['0.8416', '0.8938']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.72it/s]\n",
      "2022-07-04 17:47:28.278 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.1011 test 0.3174 metric ['0.8462', '0.9044']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.42it/s]\n",
      "2022-07-04 17:47:33.437 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.1373 test 0.3212 metric ['0.8349', '0.8994']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.99it/s]\n",
      "2022-07-04 17:47:38.242 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.1299 test 0.3044 metric ['0.8376', '0.9069']\n",
      "100%|██████████| 25/25 [00:03<00:00,  7.40it/s]\n",
      "2022-07-04 17:47:42.863 | INFO     | src.training.train_model:trainloop:164 - Epoch 20 train 0.1485 test 0.3928 metric ['0.8082', '0.8806']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.89it/s]\n",
      "2022-07-04 17:47:47.740 | INFO     | src.training.train_model:trainloop:164 - Epoch 21 train 0.1640 test 0.3271 metric ['0.8450', '0.9050']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.98it/s]\n",
      "2022-07-04 17:47:52.536 | INFO     | src.training.train_model:trainloop:164 - Epoch 22 train 0.1470 test 0.3245 metric ['0.8315', '0.8962']\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.84it/s]\n",
      "2022-07-04 17:47:57.399 | INFO     | src.training.train_model:trainloop:164 - Epoch 23 train 0.1545 test 0.3191 metric ['0.8306', '0.8944']\n",
      "100%|██████████| 25/25 [00:04<00:00,  6.23it/s]\n",
      "2022-07-04 17:48:02.749 | INFO     | src.training.train_model:trainloop:164 - Epoch 24 train 0.1674 test 0.3004 metric ['0.8627', '0.9131']\n",
      "100%|██████████| 25/25 [02:06<00:00,  5.05s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=25,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-2,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:Green\">*Uitkomsten experiment*</span> \n",
    "\n",
    "Voor het RNN-model met attention layer zijn de meest succesvolle variabelen gebruikt op basis van de eerder beschreven experimenten. Doordat het model in eerste instantie slechter scoorde dat het RNN-model zónder attention layer, heb ik besloten om meerdere runs te draaien om een goede indruk te verkrijgen van het model. Doordat er gebruik wordt gemaakt van een streamer, wordt bij iedere run namelijk een andere dataset aangeboden waardoor het model, op basis van dezelfde variabelen, anders kan presteren.\n",
    "\n",
    "<img src=\"../figures/Experiment_5_Attention_Layer.png\">\n",
    "\n",
    "Op basis van bovenstaande uitkomsten is goed inzichtelijk dat het model een mooie score heeft behaald, maar op basis van de Loss/test score nog minder presteert dan het model zonder de attention layer.   Een mogelijke uitkomst hiervan kan zijn dat het model met attention layer andere variabelen nodig heeft om optimaal te presteren. Derhalve heb ik besloten om op basis van de ervaringen van de voorgaande analyse nog een vijftien-tal experimenten uit te voeren om een betere score te bereiken. In onderstaande tabel zijn alle variabelen weergegeven die tijdens de trainsessies zijn toegepast inclusief de tijdsduur per trainsessie en de scores van het model:\n",
    "\n",
    "<img src=\"../figures/Experiment_5_Attention_Layer_extra.png\">\n",
    "\n",
    "Kijkend naar de loss/test, accuracy en F1-score is het gelukt om het model nog net iets beter te laten presteren. De uitkomsten zijn in bovenstaande tabel in groen gemarkeerd.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:Green\">*Conclusie*</span> \n",
    "\n",
    "De hiervoor beschreven experimenten heb ik als zeer leerzaam ervaren. Middels het handmatig 'tunen' van een model heb ik een goed beeld verkregen welke invloed parameters kunnen hebben op een model. Het gestructureerd vastleggen van de gebruikte parameters in combinatie met de visualisaties in TenserBoard zorgen ervoor dat de veranderingen in uitkomsten goed geïntepreteerd kunnen worden en daarbij beter kan worden bijgestuurd tijdens de experimenten. Vooral de uitkomsten van het experimenten met de learning rate en optimizers vond ik interessant doordat goed wordt weergegeven hoe gevoelig een model kan zijn voor kleine wijzigingen. Wel had ik verwacht dat het toevoegen van een attention layer een grotere impact zou hebben op de werking van het model. Een kleine disclaimer hierbij is dat ik heb gemerkt dat de uitkomsten van de experimenten tussentijds kunnen verschillen, doordat de input per run varieert."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-DDG3aTJy-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ef7eee7c1ffccdb050f8336de9a04a9ab88c4d3eb3bee3e0a27c87a184d1d38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
